{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d73d674e",
   "metadata": {},
   "source": [
    "### Contents  \n",
    "**_I. Data preprocessing_**\n",
    "> 1. Read dataset  \n",
    "> 2. Missing values handling\n",
    ">> a) `train.csv`  \n",
    ">> b) `test.csv`\n",
    "> 3. Data manipulation\n",
    ">> a) `Date`  \n",
    ">> b) `IsHoliday`  \n",
    ">> c) `Store`  \n",
    ">> d) `Promotion1`, ... , `Promotion5`\n",
    "> 4. Add new features\n",
    "> 5. Remove not using features  \n",
    "\n",
    "**_II. Modeling_**  \n",
    "> 1. Divide `train.csv` into training data and predicting data\n",
    "> 2. Choose a suitable model\n",
    ">> a) XGBooster  \n",
    ">> b) Random Forest  \n",
    "\n",
    "**_III. Submission_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b491ffaf",
   "metadata": {},
   "source": [
    "----\n",
    "# I. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2034d",
   "metadata": {},
   "source": [
    "## 1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "128e1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"dataset/train.csv\")\n",
    "test = pd.read_csv(\"dataset/test.csv\")\n",
    "submission = pd.read_csv(\"dataset/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbfaac",
   "metadata": {},
   "source": [
    "## 2. Missing values handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a8a773",
   "metadata": {},
   "source": [
    "### a) `train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2685bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c34093",
   "metadata": {},
   "source": [
    "### b) `test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d62391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {\n",
    "    \"Promotion1\":test[\"Promotion1\"].mean(), \"Promotion2\":test[\"Promotion2\"].mean(), \n",
    "    \"Promotion3\":test[\"Promotion3\"].mean(), \"Promotion4\":test[\"Promotion4\"].mean(), \n",
    "    \"Promotion5\":test[\"Promotion5\"].mean()\n",
    "}\n",
    "test = test.fillna(value=means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ffd826",
   "metadata": {},
   "source": [
    "## 3. Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faea470",
   "metadata": {},
   "source": [
    "### a) `Date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0243e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_manipulate(date):\n",
    "    return tuple(map(int, date.split('/')))\n",
    "\n",
    "# train\n",
    "train[\"Day\"] = train[\"Date\"].apply(lambda x: date_manipulate(x)[0])\n",
    "train[\"Month\"] = train[\"Date\"].apply(lambda x: date_manipulate(x)[1])\n",
    "train[\"Year\"] = train[\"Date\"].apply(lambda x: date_manipulate(x)[2])\n",
    "\n",
    "# test\n",
    "test[\"Day\"] = test[\"Date\"].apply(lambda x: date_manipulate(x)[0])\n",
    "test[\"Month\"] = test[\"Date\"].apply(lambda x: date_manipulate(x)[1])\n",
    "test[\"Year\"] = test[\"Date\"].apply(lambda x: date_manipulate(x)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea7d458",
   "metadata": {},
   "source": [
    "### b) `IsHoliday`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "515e1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"IsHoliday\"] = train[\"IsHoliday\"].apply(int)\n",
    "test[\"IsHoliday\"] = test[\"IsHoliday\"].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b42a4",
   "metadata": {},
   "source": [
    "### c) `Store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d2994cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(data=train, columns=[\"Store\"])\n",
    "test = pd.get_dummies(data=test, columns=[\"Store\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62e66f",
   "metadata": {},
   "source": [
    "### d) `Promotion1`, ... , `Promotion5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e0daf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# train\n",
    "scaler = QuantileTransformer(n_quantiles = 6255)\n",
    "\n",
    "scaler.fit(train[['Promotion1','Promotion2','Promotion3','Promotion4','Promotion5']])\n",
    "scaled = scaler.transform(train[['Promotion1','Promotion2','Promotion3','Promotion4','Promotion5']])\n",
    "train[['Scaled_Promotion1','Scaled_Promotion2','Scaled_Promotion3','Scaled_Promotion4','Scaled_Promotion5']] = scaled\n",
    "\n",
    "# test\n",
    "scaler = QuantileTransformer(n_quantiles = 180)\n",
    "\n",
    "scaler.fit(test[['Promotion1','Promotion2','Promotion3','Promotion4','Promotion5']])\n",
    "scaled = scaler.transform(test[['Promotion1','Promotion2','Promotion3','Promotion4','Promotion5']])\n",
    "test[['Scaled_Promotion1','Scaled_Promotion2','Scaled_Promotion3','Scaled_Promotion4','Scaled_Promotion5']] = scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aef898",
   "metadata": {},
   "source": [
    "## 4. Add new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ab6fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "social_features = [\"Temperature\",\"Fuel_Price\",\"Unemployment\"]\n",
    "dummy = train[social_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85389a7",
   "metadata": {},
   "source": [
    "## 5. Remove not using features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df8eb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['id','Date','Promotion1','Promotion2','Promotion3','Promotion4','Promotion5'])\n",
    "train = train.drop(columns=social_features)\n",
    "\n",
    "test = test.drop(columns=['id','Date','Promotion1','Promotion2','Promotion3','Promotion4','Promotion5'])\n",
    "test = test.drop(columns=social_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4806e6df",
   "metadata": {},
   "source": [
    "----\n",
    "# II. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f106b",
   "metadata": {},
   "source": [
    "## 1. Divide `train.csv` into training data and for predicting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78b4e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns=[\"Weekly_Sales\"])\n",
    "y_train = train[\"Weekly_Sales\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9b2dc",
   "metadata": {},
   "source": [
    "## 2. Choose a suitable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74027679",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd684312",
   "metadata": {},
   "source": [
    "### a) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d80b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost] => time: 2.26(sec)\n",
      "1667082.75, 1544718.5, ... , 809487.3125\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "start_t = time.time()\n",
    "model = XGBRegressor(objective='reg:squarederror', learning_rate=0.1, max_depth = 4, n_estimators = 1000)\n",
    "model.fit(x_train, y_train)\n",
    "prediction = model.predict(test)\n",
    "predictions[\"XGBoost\"] = prediction\n",
    "\n",
    "print(f\"[XGBoost] => time: {round(time.time() - start_t, 2)}(sec)\")\n",
    "print(f\"{prediction[0]}, {prediction[1]}, ... , {prediction[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab83f84c",
   "metadata": {},
   "source": [
    "### b) Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "869d49ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RandomForest] => time: 3.64(sec)\n",
      "1633769.4414000004, 1509749.520200001, ... , 783806.6269999999\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "start_t = time.time()\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "prediction = model.predict(test)\n",
    "predictions[\"RandomForest\"] = prediction\n",
    "\n",
    "print(f\"[RandomForest] => time: {round(time.time() - start_t, 2)}(sec)\")\n",
    "print(f\"{prediction[0]}, {prediction[1]}, ... , {prediction[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a880c",
   "metadata": {},
   "source": [
    "----\n",
    "# III. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cf6f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "def name(integer):\n",
    "    return str(integer).zfill(2)\n",
    "    \n",
    "savetime = datetime.datetime.now()\n",
    "folder = \"-\".join(map(name, [savetime.year, savetime.month, savetime.day]))\n",
    "sub_folder = name(savetime.hour) + '：' + name(savetime.minute) + '：' + name(savetime.second)\n",
    "\n",
    "for model in predictions:\n",
    "    submission[\"Weekly_Sales\"] = predictions[model]\n",
    "    os.makedirs(f\"dataset/submissions/{folder}/{sub_folder}\", exist_ok=True)\n",
    "    submission.to_csv(f\"dataset/submissions/{folder}/{sub_folder}/{model}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af93dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
