{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b491ffaf",
   "metadata": {},
   "source": [
    "----\n",
    "# I. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d2034d",
   "metadata": {},
   "source": [
    "## 1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "128e1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"../dataset/train.csv\")\n",
    "test = pd.read_csv(\"../dataset/test.csv\")\n",
    "submission = pd.read_csv(\"../dataset/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbfaac",
   "metadata": {},
   "source": [
    "## 2. Missing values handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a8a773",
   "metadata": {},
   "source": [
    "### a) `train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2685bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def means(df):\n",
    "    res = {}\n",
    "    for i in range(1, 6):\n",
    "        res[f\"Promotion{i}\"] = df[f\"Promotion{i}\"].mean()\n",
    "    return res\n",
    "\n",
    "\n",
    "def medians(df):\n",
    "    res = {}\n",
    "    for i in range(1, 6):\n",
    "        res[f\"Promotion{i}\"] = df[f\"Promotion{i}\"].median()\n",
    "    return res\n",
    "\n",
    "\n",
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c34093",
   "metadata": {},
   "source": [
    "### b) `test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d62391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(value=means(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ffd826",
   "metadata": {},
   "source": [
    "## 3. Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faea470",
   "metadata": {},
   "source": [
    "### a) `Date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0243e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "def date_to_week(date):\n",
    "    day, month, year = map(int, date.split('/'))\n",
    "    t = dt.datetime(year, month, day) - dt.datetime(2010, 2, 5)\n",
    "    return int(t.days // 7)\n",
    "\n",
    "\n",
    "def date_split(date):\n",
    "    return tuple(map(int, date.split('/')))\n",
    "\n",
    "\n",
    "# train\n",
    "train['Week'] = train['Date'].apply(date_to_week)\n",
    "train[\"Day\"] = train[\"Date\"].apply(lambda x: date_split(x)[0])\n",
    "train[\"Month\"] = train[\"Date\"].apply(lambda x: date_split(x)[1])\n",
    "train[\"Year\"] = train[\"Date\"].apply(lambda x: date_split(x)[2])\n",
    "\n",
    "\n",
    "# test\n",
    "test['Week'] = test['Date'].apply(date_to_week)\n",
    "test[\"Day\"] = test[\"Date\"].apply(lambda x: date_split(x)[0])\n",
    "test[\"Month\"] = test[\"Date\"].apply(lambda x: date_split(x)[1])\n",
    "test[\"Year\"] = test[\"Date\"].apply(lambda x: date_split(x)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea7d458",
   "metadata": {},
   "source": [
    "### b) `IsHoliday`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "515e1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trian\n",
    "train[\"IsHoliday\"] = train[\"IsHoliday\"].apply(int)\n",
    "\n",
    "# test\n",
    "test[\"IsHoliday\"] = test[\"IsHoliday\"].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62e66f",
   "metadata": {},
   "source": [
    "### c) `Promotion1`, ... , `Promotion5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e0daf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "promos = ['Promotion1','Promotion2','Promotion3','Promotion4','Promotion5']\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(train[promos])\n",
    "train[promos] = scaler.transform(train[promos])\n",
    "test[promos] = scaler.transform(test[promos])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9f1dc",
   "metadata": {},
   "source": [
    "### d) Data Scaling to all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23be48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "train[\"Weekly_Sales\"] = np.log1p(train[\"Weekly_Sales\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85389a7",
   "metadata": {},
   "source": [
    "## 4. Remove not using features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df8eb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "removes = ['id','Date','Temperature'] \n",
    "\n",
    "train = train.drop(columns=removes)\n",
    "test = test.drop(columns=removes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6667509e",
   "metadata": {},
   "source": [
    "## 5. Divide by Store-trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ff7ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(df, stores):\n",
    "    divided = pd.DataFrame()\n",
    "    for store in stores:\n",
    "        divided = pd.concat([divided, df[df[\"Store\"] == store].copy()])\n",
    "    return divided\n",
    "\n",
    "\n",
    "# def remove(df, stores):\n",
    "#     for store in stores:\n",
    "#         df = df.drop(df[df[\"Store\"] == store].index)\n",
    "#     return df\n",
    "    \n",
    "\n",
    "def store_one_hot(df):\n",
    "    return pd.get_dummies(data=df, columns=[\"Store\"])\n",
    "\n",
    "\n",
    "trainA = divide(train, [36])\n",
    "testA = divide(test, [36])\n",
    "\n",
    "trainA = trainA[['Day','Month','Week','Weekly_Sales']]\n",
    "testA = testA[['Day','Month','Week']]\n",
    "\n",
    "train = store_one_hot(train)\n",
    "test = store_one_hot(test)\n",
    "\n",
    "train = train.drop(columns=['Week'])\n",
    "test = test.drop(columns=['Week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4806e6df",
   "metadata": {},
   "source": [
    "----\n",
    "# II. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f106b",
   "metadata": {},
   "source": [
    "## 1. Divide `train.csv` into training data and for predicting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78b4e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pred(df):\n",
    "    x_df = df.drop(columns=[\"Weekly_Sales\"])\n",
    "    y_df = df[\"Weekly_Sales\"]\n",
    "    return x_df, y_df\n",
    "    \n",
    "\n",
    "x_train, y_train = split_pred(train)\n",
    "x_trainA, y_trainA = split_pred(trainA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e9b2dc",
   "metadata": {},
   "source": [
    "## 2. Modeling for each stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74027679",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd684312",
   "metadata": {},
   "source": [
    "### a) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d80b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290243.55912224 285468.64658678 280772.28777095 276153.19036063]\n",
      "[XGBoost] => time: 2.13(sec)\n",
      "1682026.125, 1520418.875, ... , 789814.4375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression as linear\n",
    "\n",
    "\n",
    "start_t = time.time()\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror', \n",
    "    learning_rate=0.1, \n",
    "    max_depth = 4, \n",
    "    n_estimators = 1000\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = np.expm1(model.predict(test))\n",
    "\n",
    "\n",
    "model = linear()\n",
    "model.fit(x_trainA, y_trainA)\n",
    "pred = np.expm1(model.predict(testA))\n",
    "print(pred)\n",
    "\n",
    "\n",
    "y_pred[35*4:36*4] = pred\n",
    "\n",
    "\n",
    "predictions[\"XGBoost\"] = y_pred\n",
    "\n",
    "print(f\"[XGBoost] => time: {round(time.time() - start_t, 2)}(sec)\")\n",
    "print(f\"{y_pred[0]}, {y_pred[1]}, ... , {y_pred[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a880c",
   "metadata": {},
   "source": [
    "----\n",
    "# III. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cf6f200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done!] Create 1 csv file(s)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def name(integer):\n",
    "    return str(integer).zfill(2)\n",
    "\n",
    "\n",
    "savetime = dt.datetime.now()\n",
    "folder = \"-\".join(map(name, [savetime.year, savetime.month, savetime.day]))\n",
    "sub_folder = name(savetime.hour) + '：' + name(savetime.minute) + '：' + name(savetime.second)\n",
    "\n",
    "for model in predictions:\n",
    "    submission[\"Weekly_Sales\"] = predictions[model]\n",
    "    os.makedirs(f\"../dataset/submissions/{folder}\", exist_ok=True)\n",
    "    submission.to_csv(f\"../dataset/submissions/{folder}/{sub_folder+' ('+model+')'}.csv\", index=False)\n",
    "print(f\"[Done!] Create {len(predictions)} csv file(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af93dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
